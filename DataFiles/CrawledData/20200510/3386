https://nlp.lab.uic.edu/nlp-research/human-robot-interaction
Human-Robot Interaction | Natural Language Processing Laboratory | University of Illinois at Chicago                        Skip to the content of this page ,  the main menu , the secondary menu , the site search form , the site home page .        UIC Logo        Natural Language Processing Laboratory     Search the site     Toggle Menu      Search                  UIC Logo          Natural Language Processing Laboratory      Natural Language Processing Laboratory   Main Menu    Research    Expand Research menu           Methodology and Foundational Work    NL for Educational Technology    Summarization for Entertainment and Healthcare    Human-Robot Interaction         People    Publications    Resources    Photos    News     Eyebrow menu    Computer Science    College of Engineering    Contact    UIC menu    UIC.edu    Campus Map       Search                 View Menu  Down arrow icon            Breadcrumbs   Natural Language Processing Laboratory    Research    Human-Robot Interaction        Human-Robot Interaction       Human-robot interaction      Image: Wikipedia    In the last few years, the RoboHelper project (supported by NSF award IIS 0905593) has explored the development of robots tailored to the needs of the elderly ( Di Eugenio et al., 2010a ). We collected the multimodal ELDERLY-AT-HOME corpus, where one assistant collaborates with an elderly person in performing Activities of Daily Living (ADLs). The project has focused on building a multimodal interface for communication between the elderly person and the robot, since our data collection confirms that beyond language, gestures and haptic actions (gestures that involve touch) are pervasive in this sort of interaction. The corpus has been annotated for a variety of information and will be made available in due course. We have developed a multimodal dialogue manager that performs multimodal reference resolution ( Chen & Di Eugenio, 2012 ), models the fact that these interactions comprise not only dialogue acts but also physical actions, and predicts the next dialogue act on the basis of the preceding multimodal signals (Chen & Di Eugenio, 2013).          Research    Back to main content           Methodology and Foundational Work    NL for Educational Technology    Summarization for Entertainment and Healthcare    Human-Robot Interaction                   UIC Logo         Computer  Science  College Of  Engineering         Contact   Natural Language Processing Laboratory  bdieugen@uic.edu        Social Media Accounts            UIC.edu links   UIC.edu  Academic Calendar  Athletics  Campus Directory  Disability Resources  Emergency Information  Event Calendar  Job Openings  Library  Maps  UIC Safe Mobile App  UIC Today  UI Health  Veterans Affairs        Powered by Red 2.38.0  © 2020 The Board of Trustees of the University of Illinois |  Privacy Statement    Campuses   University of Illinois System  Urbana-Champaign  Springfield      Cookie Settings                 