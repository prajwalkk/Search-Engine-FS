https://engineering.uic.edu/news-stories/brent-stephens-receives-nsf-career-award-for-work-in-computer-science
Brent Stephens receives NSF CAREER award for work in computer science | College of Engineering | University of Illinois at Chicago                        Skip to the content of this page ,  the main menu , the site search form , the site home page .        UIC Logo        College of Engineering     Search the site     Toggle Menu      Search                  UIC Logo          College of Engineering      College of Engineering   Main Menu    Undergraduate    Expand Undergraduate menu           Admitted Student Information    Admissions    Advising    Career Outcomes    Diversity    Engineering Expo    FAQ    Majors and Minors    Paid Internships    Scholarships    Student Groups    Student Resources    Women in Engineering         Graduate    Departments    Research    Expand Research menu           Interdisciplinary Research    Labs and Centers         Support UIC    Expand Support UIC menu           Donate Online    How to Give    Help Students    Empower Faculty    Capital Projects         About    Expand About menu           Dean    Faculty    Administration    Staff    Alumni    Advisory Board    Facilities    Summer Camp    News    Contact          Eyebrow menu    Give    Careers    Alumni    UIC menu    UIC.edu    Campus Map       Search                       Brent Stephens receives NSF CAREER award for work in computer science    by Andrea Poet  |  Posted on April 30, 2020         Brent Stephens receives NSF CAREER award for work in computer science   Brent Stephens, assistant professor of computer science, has received a $500,000 National Science Foundation CAREER award. His project aims to rethink the way that distributed computing systems are implemented and deployed.  The CAREER award is the National Science Foundation’s most prestigious honor in support of early-career faculty. Since arriving at UIC, Stephens has received two other grants in support of his work. He received a Google Faculty Award in 2018 and the following year received a $175,000 NSF Computer and Information Science and Engineering Research Initiation Initiative (CRII) grant.  Stephens came to UIC in 2018 after working for several years as a postdoctoral researcher at the University of Wisconsin at Madison. He earned his PhD in computer science at Rice University. His work is largely at the intersection of networking, operating systems, and computer architecture.  More specifically, Stephens is focused on addressing one of the biggest challenges in computing today: the need to scale application performance. Scaling application performance is key not only to support the continued growth of important existing services in computing such as search and email, but also to enable new computationally intense applications that rely on machine learning, such as self-driving cars.  Unfortunately, it is no longer possible to scale application performance by improving the efficiency of a single computer. For more than 40 years, that had been the case. Transistors became ever smaller, allowing the density of transistors on each microchip to double roughly every two years. These more powerful chips increased the speed of central processing units, or CPUs—the part of a computer where most calculations take place—by 40 percent, without a corresponding increase in power consumption. Today, CPUs have reached the upper limits of those gains. According to Stephens, a single computing core within a network can generate about 35 to 40 gigabits per second (Gbps), which can also be quantified as six million packets per second—a level of performance that has not changed significantly over the past five years. By contrast, the performance of networks as a whole is continuing to increase: exponentially, in fact, to rates of 100 gigabits per second and beyond.  “This means there is an ever-increasing gap in between the amount of data we can consume, process, and generate on a CPU, and the amount of data the network can carry,” Stephens explained.  To address the problems created by this performance gap, Stephens is working on a few research projects that share a common theme. He is moving computation from computers attached to the network into the network itself, which can overcome the limitations of existing systems, and he’s continuing to scale application-level performance to meet the needs of existing and emerging applications.  Stephens’ CAREER award proposal, titled “NIC-Accelerated Active Messaging as a Generic Replacement for RDMA,” is an extension of the work he did with his Google grant. In this project, he is rethinking the design of server-side networking with a new networking framework called Network Interface Card (NIC) Accelerated Active Messaging (NAAM).  In NAAM, functions are written in a high-level language, then compiled to a bytecode, which is a simple, faster code for processing, and verified before they are executed on a network interface card. This new paradigm enables accelerating message processing and offloading of computation from the main processors, while providing a simple and expressive interface to application programmers.  Stephens sees this as an improvement over Remote Direct Memory Access, or RDMA, an existing technology that allows computers in a network to exchange data in main memory without involving the processor of either computer. While RDMA is fast, it presents challenges for developers and suffers from harmful performance variations that are hard to predict.  “RDMA network cards have advanced functionality, but no one is willing to use them because they are difficult to use, and the underlying network is essentially incompatible with them,” Stephens said.  His first NSF grant focuses on a related area: controlling the flow of data in a network to prevent packet loss, which occurs when one or more packets of data travelling across a computer network fail to reach their destination.  “As soon as your input rate is greater than your service rate, things are going to continue piling up, which is called congestion,” Stephens said. “Buffer space isn’t infinite in computers, so that’s really where packet loss comes from.”  While cutting down on packet loss will help, a shift to a new networking framework can solve some of the limitations present in current hardware and improve server-utilization efficiency, Stephens believes.  “Buying lots of servers and not using them all is wasteful, especially from an environmental perspective,” he said. “A lot of this push comes from extracting as much performance as we can from these servers.” He added: “It’s about creating new programming paradigms and frameworks for executing these programs as well as new approaches for handling congestion that overcome these non-starter limitations on current RDMA hardware.”  For more on Stephens, visit his website at https://www.cs.uic.edu/~brents/                      UIC Logo         College of  Engineering            Contact   College of Engineering  851 S. Morgan St., MC 159, Chicago, IL 60607  Phone: (312) 996-3463  uic-engr@uic.edu        Social Media Accounts    Facebook    LinkedIn    Twitter    Instagram    YouTube             UIC.edu links   UIC.edu  Academic Calendar  Athletics  Campus Directory  Disability Resources  Emergency Information  Event Calendar  Job Openings  Library  Maps  UIC Safe Mobile App  UIC Today  UI Health  Veterans Affairs        Powered by Red 2.38.0  © 2020 The Board of Trustees of the University of Illinois |  Privacy Statement    Campuses   University of Illinois System  Urbana-Champaign  Springfield      Cookie Settings                   